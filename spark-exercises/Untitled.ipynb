{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[title: string, body: string, FROM_UNIXTIME: string]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.types import StructField, StringType, StructType\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "labels = [\"title\",\"body\",\"FROM_UNIXTIME\"]\n",
    "\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in labels]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Loads data.\n",
    "data_df = spark.read.csv(\"/home/marcos/code/data/noticias_small.csv\", schema=schema)\n",
    "#.map(lambda row: row.split(\"\\r\\n\"))\n",
    "print(data_df)\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "wordsDataFrame = tokenizer.transform(data_df)\n",
    "\n",
    "stopWords = StopWordsRemover.loadDefaultStopWords(\"portuguese\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_filtered\", stopWords = stopWords)\n",
    "wordsFiltered = remover.transform(wordsDataFrame)\n",
    "\n",
    "cv_tmp = CountVectorizer(inputCol=\"words_filtered\", outputCol=\"tmp_vectors\")\n",
    "cv_tmp_model = cv_tmp.fit(wordsFiltered)\n",
    "df_vect = cv_tmp_model.transform(wordsFiltered)\n",
    "\n",
    "def parseVectors(line):\n",
    "    return [int(line[2]), line[1]]\n",
    "\n",
    "sparsevector = df_vect.select(\"FROM_UNIXTIME\", \"tmp_vectors\")\n",
    "\n",
    "lda = LDA(k=10, maxIter=5, featuresCol=\"tmp_vectors\")\n",
    "ldaModel = lda.fit(sparsevector)\n",
    "topics = ldaModel.topicsMatrix()\n",
    "# model = LDA.train(sparsevector, k=5, seed=1)\n",
    "\n",
    "# Describe topics.\n",
    "topics = ldaModel.describeTopics(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------------------------------------------------------------------+\n",
      "|topic|termIndices    |termWeights                                                          |\n",
      "+-----+---------------+---------------------------------------------------------------------+\n",
      "|0    |[344, 512, 356]|[0.0015499128539677857, 0.0015376121897656258, 0.001534578266471104] |\n",
      "|1    |[18, 30, 65]   |[0.0022911604122462727, 0.001960418125507248, 0.0018349997465317437] |\n",
      "|2    |[786, 488, 233]|[0.0015630183260770532, 0.001526854272085165, 0.0014876709358065464] |\n",
      "|3    |[694, 472, 278]|[0.0015284687573058132, 0.0014744810916764734, 0.0014590275131129385]|\n",
      "|4    |[26, 41, 59]   |[0.0021430016431183575, 0.0020186395596801013, 0.0019869963503508]   |\n",
      "|5    |[299, 52, 79]  |[0.001565406743621223, 0.0015238536866013536, 0.0015172878531468001] |\n",
      "|6    |[40, 20, 13]   |[0.002642871084424427, 0.002399134704608303, 0.002290245868006309]   |\n",
      "|7    |[1, 0, 2]      |[0.003685734064449033, 0.0031930043088975804, 0.0030815629700028484] |\n",
      "|8    |[0, 1, 3]      |[0.0024204367399162097, 0.002315259939465752, 0.001998827077211851]  |\n",
      "|9    |[1, 9, 0]      |[0.0017223427246199773, 0.0016778507164460607, 0.0016770266662562534]|\n",
      "+-----+---------------+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic nr: 0\n",
      "Column<b\"topic['termIndices']['row'][0]\">\n",
      "topic nr: 1\n",
      "Column<b\"termIndices['termIndices']['row'][0]\">\n",
      "topic nr: 2\n",
      "Column<b\"termWeights['termIndices']['row'][0]\">\n"
     ]
    }
   ],
   "source": [
    "for x, topic in enumerate(topics):\n",
    "    print('topic nr: ' + str(x))\n",
    "    words = topic[\"termIndices\"]\n",
    "    print(words.row[0])\n",
    "    weights = topic[\"termWeights\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
